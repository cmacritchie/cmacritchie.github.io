{"version":3,"file":"static/webpack/static\\development\\pages\\project\\scraping.js.10d3a60856f2cf96c6b8.hot-update.js","sources":["webpack:///./pages/project/scraping.js"],"sourcesContent":["import PageLayout from '../../HOC/pageLayout'\r\n\r\n\r\nconst pageDetails = {\r\n    title: 'Sedi Web Scraping',\r\n    back:'/#projects',\r\n    next:'/project/tracker',\r\n    nextTitle:'Tracker App'\r\n  }\r\n\r\nconst LouisRiel = () => {\r\n    return (\r\n        <PageLayout pageDetails={pageDetails}>\r\n            <p>\r\n                For my application to Mawer Investment Management I was given a programming challenge as part of\r\n                my interview process. The challenge was to get all the Insider information from the SEDI website\r\n                on all the insiders. To do this I wrote a Python Application using the HTML parsing library: \r\n                'Beautiful soup', from there I was able to retrieve all of the insiders and save their \r\n                information in a MySQL database       \r\n            </p>    \r\n        </PageLayout>\r\n    )\r\n}\r\n\r\nexport default LouisRiel"],"mappings":";;;;;;;;;;;;;;;;;AAAA;AAGA;AACA;AACA;AACA;AACA;AAJA;AACA;AAMA;AACA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AASA;AACA;AACA;;;;A","sourceRoot":""}
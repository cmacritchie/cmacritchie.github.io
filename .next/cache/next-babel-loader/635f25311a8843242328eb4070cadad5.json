{"ast":null,"code":"var _jsxFileName = \"C:\\\\Users\\\\747049\\\\Desktop\\\\craigio\\\\pages\\\\project\\\\scraping.js\";\nimport React from \"react\";\nvar __jsx = React.createElement;\nimport PageLayout from '../../HOC/pageLayout';\nconst pageDetails = {\n  title: 'Sedi Web Scraping',\n  back: '/#projects',\n  next: '/project/tracker',\n  nextTitle: 'Tracker App'\n};\n\nconst LouisRiel = () => {\n  return __jsx(PageLayout, {\n    pageDetails: pageDetails,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 13\n    },\n    __self: this\n  }, __jsx(\"p\", {\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 14\n    },\n    __self: this\n  }, \"For my application to Mawer Investment Management I was given a programming challenge as part of my interview process. The challenge was to get all the Insider information from the SEDI website on all the insiders. To do this I wrote a Python Application using the HTML parsing library: 'Beautiful soup', from there I was able to retrieve all of the insiders and save their information in a MySQL database\"));\n};\n\nexport default LouisRiel;","map":{"version":3,"sources":["C:/Users/747049/Desktop/craigio/pages/project/scraping.js"],"names":["PageLayout","pageDetails","title","back","next","nextTitle","LouisRiel"],"mappings":";;;AAAA,OAAOA,UAAP,MAAuB,sBAAvB;AAGA,MAAMC,WAAW,GAAG;AAChBC,EAAAA,KAAK,EAAE,mBADS;AAEhBC,EAAAA,IAAI,EAAC,YAFW;AAGhBC,EAAAA,IAAI,EAAC,kBAHW;AAIhBC,EAAAA,SAAS,EAAC;AAJM,CAApB;;AAOA,MAAMC,SAAS,GAAG,MAAM;AACpB,SACI,MAAC,UAAD;AAAY,IAAA,WAAW,EAAEL,WAAzB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,KACI;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,6ZADJ,CADJ;AAWH,CAZD;;AAcA,eAAeK,SAAf","sourcesContent":["import PageLayout from '../../HOC/pageLayout'\r\n\r\n\r\nconst pageDetails = {\r\n    title: 'Sedi Web Scraping',\r\n    back:'/#projects',\r\n    next:'/project/tracker',\r\n    nextTitle:'Tracker App'\r\n  }\r\n\r\nconst LouisRiel = () => {\r\n    return (\r\n        <PageLayout pageDetails={pageDetails}>\r\n            <p>\r\n                For my application to Mawer Investment Management I was given a programming challenge as part of\r\n                my interview process. The challenge was to get all the Insider information from the SEDI website\r\n                on all the insiders. To do this I wrote a Python Application using the HTML parsing library: \r\n                'Beautiful soup', from there I was able to retrieve all of the insiders and save their \r\n                information in a MySQL database       \r\n            </p>    \r\n        </PageLayout>\r\n    )\r\n}\r\n\r\nexport default LouisRiel"]},"metadata":{},"sourceType":"module"}